{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Parallel Network using LFPy\n",
    "\n",
    "This example notebook submits a job to a chosen compute cluster (**JUSUF**), loads a **Singularity** container with a working **LFPy** installation and executes a version of the LFPy example file ``example_network.py`` (https://github.com/LFPy/LFPy/blob/master/examples/example_network/example_network.py) in parallel on one HPC backend of EBRAINS/HBP.\n",
    "\n",
    "The example demonstrates usage of ``LFPy.Network`` with network of ball-and-stick type\n",
    "morphologies with active HH channels inserted in the somas and passive-leak\n",
    "channels distributed throughout the apical dendrite. The corresponding\n",
    "morphology and template specifications are in the files ``BallAndStick.hoc`` and\n",
    "``BallAndStickTemplate.hoc``.\n",
    "\n",
    "\n",
    "For more indepth info on using HPC backends via EBRAINS see https://wiki.ebrains.eu/bin/view/Collabs/using-supercomputers-from-the-collab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/user/drive/Shared with groups/LFPy showcase\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pyunicore in /opt/app-root/lib/python3.6/site-packages (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.5 in /opt/app-root/lib/python3.6/site-packages (from pyunicore) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT>=1.7 in /opt/app-root/lib/python3.6/site-packages (from pyunicore) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# use the pyunicore library\n",
    "!pip install pyunicore --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import pyunicore.client as unicore_client\n",
    "import requests\n",
    "import json\n",
    "from time import sleep, time\n",
    "from pprint import pprint\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection to supercomputer (i.e., JUSUF)\n",
    "tr = unicore_client.Transport(clb_oauth.get_token())\n",
    "r = unicore_client.Registry(tr, unicore_client._HBP_REGISTRY_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RWTH': 'https://unicore.hpc.itc.rwth-aachen.de:8080/RWTH/rest/core',\n",
       " 'FZJ_JURECA': 'https://zam2125.zam.kfa-juelich.de:9112/FZJ_JURECA/rest/core',\n",
       " 'JUWELS': 'https://zam2125.zam.kfa-juelich.de:9112/JUWELS/rest/core',\n",
       " 'UNICORE-TEST': 'https://catto.cscs.ch:8080/UNICORE-TEST/rest/core',\n",
       " 'DAINT-CSCS': 'https://brissago.cscs.ch:8080/DAINT-CSCS/rest/core',\n",
       " 'BSC-MareNostrum': 'https://unicore-hbp.bsc.es:8080/BSC-MareNostrum/rest/core',\n",
       " 'irene': 'https://hbp-unicore.ccc.cea.fr/irene/rest/core',\n",
       " 'CINECA-MARCONI': 'https://grid.hpc.cineca.it:9111/CINECA-MARCONI/rest/core',\n",
       " 'CINECA-GALILEO': 'https://grid.hpc.cineca.it:9111/CINECA-GALILEO/rest/core'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valid choices for supercomputers are one of the keys in:\n",
    "r.site_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "supercomputer = 'JUSUF'\n",
    "try:\n",
    "    site_client = r.site(supercomputer)\n",
    "except KeyError:\n",
    "    # cluster may be dropped from Registry.site_urls for whatever reason\n",
    "    site_client = unicore_client.Client(r.transport, 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code 200 \n",
      "Content-type application/json \n"
     ]
    }
   ],
   "source": [
    "# check connection to supercomputer\n",
    "headers = {}\n",
    "headers[\"Authorization\"] = \"Bearer \" + clb_oauth.get_token()\n",
    "headers['Accept'] = \"application/json\"\n",
    "rs = requests.get(url=site_client.site_url, headers = headers, verify = False)\n",
    "print(\"Status code %s \" % rs.status_code)\n",
    "print(\"Content-type %s \" % rs.headers['Content-Type'])\n",
    "reply = rs.json()\n",
    "# print(json.dumps(reply, indent = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download LFPy example network files\n",
    "Prepare simulation files using example files from the main LFPy repository (https://github.com/LFPy/LFPy.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-26 12:50:31--  https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/example_network.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18899 (18K) [text/plain]\n",
      "Saving to: ‘example_network.py’\n",
      "\n",
      "100%[======================================>] 18,899      --.-K/s   in 0.01s   \n",
      "\n",
      "2020-10-26 12:50:31 (1.62 MB/s) - ‘example_network.py’ saved [18899/18899]\n",
      "\n",
      "--2020-10-26 12:50:32--  https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/BallAndStick.hoc\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 610 [text/plain]\n",
      "Saving to: ‘BallAndStick.hoc’\n",
      "\n",
      "100%[======================================>] 610         --.-K/s   in 0s      \n",
      "\n",
      "2020-10-26 12:50:32 (37.9 MB/s) - ‘BallAndStick.hoc’ saved [610/610]\n",
      "\n",
      "--2020-10-26 12:50:33--  https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/BallAndStickTemplate.hoc\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 376 [text/plain]\n",
      "Saving to: ‘BallAndStickTemplate.hoc’\n",
      "\n",
      "100%[======================================>] 376         --.-K/s   in 0s      \n",
      "\n",
      "2020-10-26 12:50:33 (16.0 MB/s) - ‘BallAndStickTemplate.hoc’ saved [376/376]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O example_network.py https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/example_network.py\n",
    "!wget -O BallAndStick.hoc https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/BallAndStick.hoc\n",
    "!wget -O BallAndStickTemplate.hoc https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/BallAndStickTemplate.hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to make things more interesting with HPCs, let's increase the network size and adjust synaptic weights by applying a patch:\n",
    "diff = '''240c240\n",
    "< population_sizes = [80, 20]\n",
    "---\n",
    "> population_sizes = [1024, 256]\n",
    "257,260c257,260\n",
    "< weightArguments = [[dict(loc=0.002, scale=0.0002),\n",
    "<                     dict(loc=0.002, scale=0.0002)],\n",
    "<                    [dict(loc=0.02, scale=0.002),\n",
    "<                     dict(loc=0.02, scale=0.002)]]\n",
    "---\n",
    "> weightArguments = [[dict(loc=0.0002, scale=0.00002),\n",
    ">                     dict(loc=0.0002, scale=0.00002)],\n",
    ">                    [dict(loc=0.002, scale=0.0002),\n",
    ">                     dict(loc=0.002, scale=0.0002)]]\n",
    "380c380\n",
    "<             ax.plot(t[t >= 200], g[t >= 200], '|', label=name)\n",
    "---\n",
    ">             ax.plot(t[t >= 200], g[t >= 200], '.', ms=2, label=name)\n",
    "'''\n",
    "\n",
    "with open('patch.diff', 'w') as f:\n",
    "    f.writelines(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patching file example_network.py\n"
     ]
    }
   ],
   "source": [
    "# apply patch\n",
    "!patch example_network.py patch.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare singularity container\n",
    "See https://gitlab.version.fz-juelich.de/bvonstvieth_publications/container_userdoc_tmp for details. \n",
    "\n",
    "This step builds the singularity container. It is optional if the recipe has already been uploaded and built on the system. \n",
    "\n",
    "The procedure may be different on different HPC backends. \n",
    "The container can either way be built from the same recipe: https://raw.githubusercontent.com/LFPy/LFPydebian/main/mpich.Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the below Raw block into Code in order to run:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# build singularity container with LFPy using a Dockerfile. \n",
    "# This step only needs to be done once per user/project (possibly). \n",
    "build_job = {\n",
    "  \"Executable\" : \"\"\"module use $OTHERSTAGES\n",
    "module --force purge\n",
    "module load Stages/2020\n",
    "module load GCC Singularity-Tools\n",
    "\n",
    "mkdir -p ~/.config/sib\n",
    "cat > ~/.config/sib/settings.ini <<'EOF'\n",
    "[config]\n",
    "url_prefix=https://sbuild-hps.fz-juelich.de/\n",
    "EOF\n",
    "\n",
    "wget https://raw.githubusercontent.com/LFPy/LFPydebian/main/mpich.Dockerfile\n",
    "sib upload ./mpich.Dockerfile lfpydebian_mpich\n",
    "sib build −−recipe−name lfpydebian_mpich −−blocking\n",
    "\"\"\",\n",
    "    \n",
    "  \"Job type\": \"interactive\",\n",
    "}\n",
    "build_job = site_client.new_job(job_description=build_job, inputs=[])\n",
    "while build_job.is_running():\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare main simulation job\n",
    "This step combines in a single session the following:\n",
    "\n",
    "- download LFPy container\n",
    "- upload simulation files from the collab\n",
    "- ask for resources (# nodes, # MPI processes, # seconds runtime)\n",
    "- execute simulation\n",
    "- zip simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with job specification and define list of input files from this Collab\n",
    "# simulation_job = {\"Job type\": \"interactive\"}\n",
    "simulation_job = {}\n",
    "simulation_inputs = [\"example_network.py\", \"BallAndStick.hoc\", \"BallAndStickTemplate.hoc\"] "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Resources\n",
    "simulation_job['Resources'] = {\n",
    "    \"Queue\": \"batch\",\n",
    "    \"Nodes\": \"1\",\n",
    "    \"CPUsPerNode\": \"256\",\n",
    "    \"CPUs\": \"128\",\n",
    "    \"Runtime\": \"600\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "simulation_job['Resources'] = {\n",
    "    \"Queue\": \"batch\",\n",
    "    \"CPUs\": \"256\",\n",
    "    \"Runtime\": \"600\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands run on login node before job execution\n",
    "simulation_job[\"User precommand\"] = \"\"\"module use $OTHERSTAGES\n",
    "module --force purge\n",
    "module load Stages/2020\n",
    "module load GCC Singularity-Tools\n",
    "sib download --recipe-name lfpydebian_mpich\n",
    "\"\"\"\n",
    "simulation_job[\"RunUserPrecommandOnLoginNode\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - set some environment variables\n",
    "# - run the python code using interpreter embedded in container\n",
    "simulation_job[\"Executable\"] = \"\"\"module use $OTHERSTAGES\n",
    "module --force purge\n",
    "module load Stages/2020\n",
    "module load GCC Singularity-Tools\n",
    "unset DISPLAY  # matplotlib may look for a nonexistant display on compute node \n",
    "srun singularity exec lfpydebian_mpich.sif python3 -u example_network.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands run after job is done\n",
    "simulation_job[\"User postcommand\"] = \"tar -cvf example_network_output.tar example_network_output\" \n",
    "simulation_job[\"RunUserPostcommandOnLoginNode\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Resources': {'Queue': 'batch', 'CPUs': '256', 'Runtime': '600'},\n",
       " 'User precommand': 'module use $OTHERSTAGES\\nmodule --force purge\\nmodule load Stages/2020\\nmodule load GCC Singularity-Tools\\nsib download --recipe-name lfpydebian_mpich\\n',\n",
       " 'RunUserPrecommandOnLoginNode': 'true',\n",
       " 'Executable': 'unset DISPLAY  # matplotlib may look for a nonexistant display on compute node \\nsrun singularity exec lfpydebian_mpich.sif python3 -u example_network.py\\n',\n",
       " 'User postcommand': 'tar -cvf example_network_output.tar example_network_output',\n",
       " 'RunUserPostcommandOnLoginNode': 'true'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create job\n",
    "job = site_client.new_job(job_description=simulation_job, inputs=simulation_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait while job is running\n",
    "while job.is_running():\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['example_network_output/', 'stderr', 'lfpydebian_mpich.sif', 'BallAndStickTemplate.hoc', 'example_network.py', 'example_network_output.tar', 'stdout', '.UNICORE_POST_0/', '.UNICORE_PRE_0/', 'UNICORE_Job_1603714221554', 'UNICORE_SCRIPT_EXIT_CODE', 'BallAndStick.hoc', 'bss_submit_1603714221554'])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.working_dir.listdir().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'/usr/local/lib/python3.7/dist-packages/LFPy/cell.py:185: UserWarning: 0 sect'\n",
      " b\"ions detected! Consider setting 'delete_sections=True'\\n\",\n",
      " b'  warn(mssg)\\n',\n",
      " b'/usr/local/lib/python3.7/dist-packages/LFPy/cell.py:185: UserWarning: 0 sect'\n",
      " b\"ions detected! Consider setting 'delete_sections=True'\\n\",\n",
      " b'  warn(mssg)\\n',\n",
      " b'/usr/local/lib/python3.7/dist-packages/LFPy/cell.py:185: UserWarning: 0 sect'\n",
      " b\"ions detected! Consider setting 'delete_sections=True'\\n\"]\n",
      "[b'  warn(mssg)\\n',\n",
      " b'/usr/local/lib/python3.7/dist-packages/LFPy/cell.py:185: UserWarning: 8 sect'\n",
      " b\"ions detected! Consider setting 'delete_sections=True'\\n\",\n",
      " b'  warn(mssg)\\n',\n",
      " b'/usr/lib/python3/dist-packages/scipy/signal/_arraytools.py:45: FutureWarning'\n",
      " b': Using a non-tuple sequence for multidimensional indexing is deprecated; us'\n",
      " b'e `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interp'\n",
      " b'reted as an array index, `arr[np.array(seq)]`, which will result either in a'\n",
      " b'n error or a different result.\\n',\n",
      " b'  b = a[a_slice]\\n']\n"
     ]
    }
   ],
   "source": [
    "# STDERR output (if any)\n",
    "stderr = job.working_dir.stat('stderr')\n",
    "pprint(stderr.raw().readlines()[:5])\n",
    "pprint(stderr.raw().readlines()[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'numprocs=256\\n',\n",
      " b'Connected population E to E by 104836 connections and 160662 synapses\\n',\n",
      " b'Connected population E to I by 26527 connections and 40752 synapses\\n',\n",
      " b'Connected population I to E by 26287 connections and 117854 synapses\\n',\n",
      " b'Connected population I to I by 6562 connections and 29530 synapses\\n',\n",
      " b'Adjusting r-distance to soma segments\\n',\n",
      " b'Adjusting r-distance to soma segments\\n',\n",
      " b'Adjusting r-distance to soma segments\\n',\n",
      " b'Adjusting r-distance to soma segments\\n',\n",
      " b'Adjusting r-distance to soma segments\\n']\n",
      "[b't = 300.0 ms\\n',\n",
      " b't = 400.0 ms\\n',\n",
      " b't = 500.0 ms\\n',\n",
      " b't = 600.0 ms\\n',\n",
      " b't = 700.0 ms\\n',\n",
      " b't = 800.0 ms\\n',\n",
      " b't = 900.0 ms\\n',\n",
      " b't = 1000.0 ms\\n',\n",
      " b't = 1100.0 ms\\n',\n",
      " b't = 1200.0 ms\\n']\n"
     ]
    }
   ],
   "source": [
    "# STDOUT output\n",
    "stdout = job.working_dir.stat('stdout')\n",
    "pprint(stdout.raw().readlines()[:10])\n",
    "pprint(stdout.raw().readlines()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download simulation output\n",
    "job.working_dir.stat('example_network_output.tar').download('example_network_output.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill job, clean up files on the remote\n",
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untar output to folder example_network_output\n",
    "!tar -xf example_network_output.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./example_network_output/extracellular_potential.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f005db4b3c8>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at e.g., the extracellular potential and spike raster plot\n",
    "IFrame(\"./example_network_output/extracellular_potential.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./example_network_output/spike_raster.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f005db4b400>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"./example_network_output/spike_raster.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
