{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Parallel Network using LFPy\n",
    "\n",
    "This example notebook submits a job to a chosen compute cluster (**JUSUF**), loads a **Singularity** container with a working **LFPy** installation and executes a version of the LFPy example file ``example_network.py`` (https://github.com/LFPy/LFPy/blob/master/examples/example_network/example_network.py) in parallel on one HPC backend of EBRAINS/HBP.\n",
    "\n",
    "The example demonstrates usage of ``LFPy.Network`` with network of ball-and-stick type\n",
    "morphologies with active HH channels inserted in the somas and passive-leak\n",
    "channels distributed throughout the apical dendrite. The corresponding\n",
    "morphology and template specifications are in the files ``BallAndStick.hoc`` and\n",
    "``BallAndStickTemplate.hoc``.\n",
    "\n",
    "\n",
    "For more indepth info on using HPC backends via EBRAINS see e.g., https://wiki.ebrains.eu/bin/view/Collabs/using-supercomputers-from-the-collab/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pyunicore==0.9.12 in /opt/app-root/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: PyJWT>=1.7 in /opt/app-root/lib/python3.6/site-packages (from pyunicore==0.9.12)\n",
      "Requirement already up-to-date: requests>=2.5 in /opt/app-root/lib/python3.6/site-packages (from pyunicore==0.9.12)\n",
      "Requirement already up-to-date: charset-normalizer~=2.0.0; python_version >= \"3\" in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore==0.9.12)\n",
      "Requirement already up-to-date: idna<4,>=2.5; python_version >= \"3\" in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore==0.9.12)\n",
      "Requirement already up-to-date: urllib3<1.27,>=1.21.1 in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore==0.9.12)\n",
      "Requirement already up-to-date: certifi>=2017.4.17 in /opt/app-root/lib/python3.6/site-packages (from requests>=2.5->pyunicore==0.9.12)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# use the pyunicore library\n",
    "!pip install pyunicore==0.9.12 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import pyunicore.client as unicore_client\n",
    "import requests\n",
    "import json\n",
    "from time import sleep, time\n",
    "from pprint import pprint\n",
    "from IPython.display import IFrame, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection to supercomputer (i.e., JUSUF)\n",
    "tr = unicore_client.Transport(clb_oauth.get_token())\n",
    "r = unicore_client.Registry(tr, unicore_client._HBP_REGISTRY_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JUWELS': 'https://zam2125.zam.kfa-juelich.de:9112/JUWELS/rest/core',\n",
       " 'JUSUF': 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core',\n",
       " 'UNICORE-TEST': 'https://catto.cscs.ch:8080/UNICORE-TEST/rest/core',\n",
       " 'BSC-MareNostrum': 'https://unicore-hbp.bsc.es:8080/BSC-MareNostrum/rest/core',\n",
       " 'JURECA': 'https://zam2125.zam.kfa-juelich.de:9112/JURECA/rest/core',\n",
       " 'DAINT-CSCS': 'https://brissago.cscs.ch:8080/DAINT-CSCS/rest/core',\n",
       " 'CINECA-MARCONI': 'https://grid.hpc.cineca.it:9111/CINECA-MARCONI/rest/core',\n",
       " 'CINECA-G100': 'https://grid.hpc.cineca.it:9111/CINECA-G100/rest/core',\n",
       " 'CINECA-M100': 'https://grid.hpc.cineca.it:9111/CINECA-M100/rest/core',\n",
       " 'JUDAC': 'https://zam2125.zam.kfa-juelich.de:9112/JUDAC/rest/core'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valid choices for supercomputers are one of the keys in:\n",
    "r.site_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to HPC resouce - change subpercomputer name to whatever you have access to:\n",
    "supercomputer = 'JUSUF'\n",
    "try:\n",
    "    site_client = r.site(supercomputer)\n",
    "except KeyError:\n",
    "    # cluster may be dropped from Registry.site_urls for whatever reason\n",
    "    site_client = unicore_client.Client(r.transport, 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': {'selected': 'user', 'availableRoles': ['user']},\n",
       " 'queues': {'availableQueues': ['batch', 'develgpus'], 'selected': 'batch'},\n",
       " 'dn': 'UID=espen.hagen@nmbu.no',\n",
       " 'xlogin': {'UID': 'hagen2',\n",
       "  'availableGroups': ['icei-hbp-2020-0004'],\n",
       "  'availableUIDs': ['hagen2'],\n",
       "  'group': 'icei-hbp-2020-0004'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_client.access_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code 200 \n",
      "Content-type application/json \n"
     ]
    }
   ],
   "source": [
    "# check connection to supercomputer\n",
    "headers = {}\n",
    "headers[\"Authorization\"] = \"Bearer \" + clb_oauth.get_token()\n",
    "headers['Accept'] = \"application/json\"\n",
    "rs = requests.get(url=site_client.site_url, headers = headers, verify = False)\n",
    "print(\"Status code %s \" % rs.status_code)\n",
    "print(\"Content-type %s \" % rs.headers['Content-Type'])\n",
    "reply = rs.json()\n",
    "# print(json.dumps(reply, indent = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download LFPy example network files\n",
    "Prepare simulation files using example files from the main LFPy repository (https://github.com/LFPy/LFPy.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-22 12:13:55--  https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/example_network.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20130 (20K) [text/plain]\n",
      "Saving to: ‘example_network.py’\n",
      "\n",
      "100%[======================================>] 20,130      --.-K/s   in 0.002s  \n",
      "\n",
      "2021-11-22 12:13:56 (8.64 MB/s) - ‘example_network.py’ saved [20130/20130]\n",
      "\n",
      "--2021-11-22 12:13:56--  https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/BallAndStick.hoc\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 610 [text/plain]\n",
      "Saving to: ‘BallAndStick.hoc’\n",
      "\n",
      "100%[======================================>] 610         --.-K/s   in 0s      \n",
      "\n",
      "2021-11-22 12:13:56 (91.8 MB/s) - ‘BallAndStick.hoc’ saved [610/610]\n",
      "\n",
      "--2021-11-22 12:13:56--  https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/BallAndStickTemplate.hoc\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 376 [text/plain]\n",
      "Saving to: ‘BallAndStickTemplate.hoc’\n",
      "\n",
      "100%[======================================>] 376         --.-K/s   in 0s      \n",
      "\n",
      "2021-11-22 12:13:56 (34.3 MB/s) - ‘BallAndStickTemplate.hoc’ saved [376/376]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O example_network.py https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/example_network.py\n",
    "!wget -O BallAndStick.hoc https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/BallAndStick.hoc\n",
    "!wget -O BallAndStickTemplate.hoc https://raw.githubusercontent.com/LFPy/LFPy/master/examples/example_network/BallAndStickTemplate.hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to make things more interesting with HPCs, let's increase the network size and adjust synaptic weights by applying a patch:\n",
    "diff = '''190c190\n",
    "< population_sizes = [256, 64]\n",
    "---\n",
    "> population_sizes = [2048, 512]\n",
    "207,210c207,210\n",
    "< weightArguments = [[dict(loc=0.001, scale=0.0001),\n",
    "<                     dict(loc=0.001, scale=0.0001)],\n",
    "<                    [dict(loc=0.01, scale=0.001),\n",
    "<                     dict(loc=0.01, scale=0.001)]]\n",
    "---\n",
    "> weightArguments = [[dict(loc=0.0005, scale=0.0001),\n",
    ">                     dict(loc=0.0005, scale=0.0001)],\n",
    ">                    [dict(loc=0.005, scale=0.001),\n",
    ">                     dict(loc=0.005, scale=0.001)]]\n",
    "'''\n",
    "\n",
    "with open('patch.diff', 'w') as f:\n",
    "    f.writelines(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patching file example_network.py\n"
     ]
    }
   ],
   "source": [
    "# apply patch\n",
    "!patch example_network.py patch.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare singularity container\n",
    "See https://gitlab.version.fz-juelich.de/bvonstvieth_publications/container_userdoc_tmp for details. \n",
    "\n",
    "This step builds the singularity container. It is optional if the recipe has already been uploaded and built on the system. \n",
    "\n",
    "The procedure may be different on different HPC backends. \n",
    "The container can either way be built from the same recipe: https://raw.githubusercontent.com/LFPy/LFPy/2.2.dev0/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the below Raw block into Code in order to run:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# build singularity container with LFPy using a Dockerfile. \n",
    "# This step only needs to be done once per user/project (possibly). \n",
    "build_job = {\n",
    "  \"Executable\" : \"\"\"module use $OTHERSTAGES\n",
    "module --force purge\n",
    "module load Stages/2020\n",
    "module load GCC Singularity-Tools\n",
    "\n",
    "#mkdir -p ~/.config/sib\n",
    "#cat > ~/.config/sib/settings.ini <<'EOF'\n",
    "#[config]\n",
    "#url_prefix=https://sbuild-hps.fz-juelich.de/\n",
    "#EOF\n",
    "\n",
    "wget https://raw.githubusercontent.com/LFPy/LFPy/master/Dockerfile\n",
    "sib upload ./Dockerfile lfpymaster\n",
    "sib build −−recipe−name lfpymaster −−blocking\n",
    "sib wait-for-completion\n",
    "\"\"\",\n",
    "    \n",
    "  \"Job type\": \"interactive\",\n",
    "}\n",
    "build_job = site_client.new_job(job_description=build_job, inputs=[])\n",
    "while build_job.is_running():\n",
    "    sleep(10)\n",
    "build_job.delete()  # delete job cleanly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare main simulation job\n",
    "This step combines in a single session the following:\n",
    "\n",
    "- download LFPy container\n",
    "- upload simulation files from the collab\n",
    "- ask for resources (# nodes, # MPI processes, # seconds runtime)\n",
    "- execute simulation\n",
    "- zip simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with job specification and define list of input files from this Collab\n",
    "# simulation_job = {\"Job type\": \"interactive\"}\n",
    "simulation_job = {}\n",
    "simulation_inputs = [\"example_network.py\", \"BallAndStick.hoc\", \"BallAndStickTemplate.hoc\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "simulation_job['Resources'] = {\n",
    "    \"Queue\": \"batch\",\n",
    "    #\"CPUs\": \"256\",\n",
    "    \"Nodes\": \"2\",\n",
    "    \"CPUsPerNode\": \"128\",\n",
    "    \"Runtime\": \"600\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands run on login node before job execution\n",
    "simulation_job[\"User precommand\"] = \"\"\"module use $OTHERSTAGES\n",
    "module --force purge\n",
    "module load Stages/2020\n",
    "module load GCC Singularity-Tools\n",
    "sib download --recipe-name lfpymaster\n",
    "\"\"\"\n",
    "simulation_job[\"RunUserPrecommandOnLoginNode\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - set some environment variables\n",
    "# - run the python code using interpreter embedded in container\n",
    "simulation_job[\"Executable\"] = \"\"\"module use $OTHERSTAGES\n",
    "module --force purge\n",
    "module load Stages/2020\n",
    "module load GCC Singularity-Tools\n",
    "unset DISPLAY  # matplotlib may look for a nonexistant display on compute node \n",
    "srun --mpi=pmi2 singularity exec lfpymaster.sif python3 -u example_network.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands run after job is done\n",
    "simulation_job[\"User postcommand\"] = \"tar -cvf example_network_output.tar example_network_output\" \n",
    "simulation_job[\"RunUserPostcommandOnLoginNode\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Resources': {'Queue': 'batch',\n",
       "  'Nodes': '2',\n",
       "  'CPUsPerNode': '128',\n",
       "  'Runtime': '600'},\n",
       " 'User precommand': 'module use $OTHERSTAGES\\nmodule --force purge\\nmodule load Stages/2020\\nmodule load GCC Singularity-Tools\\nsib download --recipe-name lfpymaster\\n',\n",
       " 'RunUserPrecommandOnLoginNode': 'true',\n",
       " 'Executable': 'module use $OTHERSTAGES\\nmodule --force purge\\nmodule load Stages/2020\\nmodule load GCC Singularity-Tools\\nunset DISPLAY  # matplotlib may look for a nonexistant display on compute node \\nsrun --mpi=pmi2 singularity exec lfpymaster.sif python3 -u example_network.py\\n',\n",
       " 'User postcommand': 'tar -cvf example_network_output.tar example_network_output',\n",
       " 'RunUserPostcommandOnLoginNode': 'true'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create job\n",
    "job = site_client.new_job(job_description=simulation_job, inputs=simulation_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'owner': 'UID=espen.hagen@nmbu.no',\n",
       " 'submissionPreferences': {'UC_OAUTH_BEARER_TOKEN': ['eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJfNkZVSHFaSDNIRmVhS0pEZDhXcUx6LWFlZ3kzYXFodVNJZ1RXaTA1U2k0In0.eyJleHAiOjE2MzgxNzczMzMsImlhdCI6MTYzNzU3MjUzMywiYXV0aF90aW1lIjoxNjM3NTY3NTAyLCJqdGkiOiI3MWRkNTNlZS00MDAxLTQ5NzMtODMzYy1kYmFiMmQyODM1NTYiLCJpc3MiOiJodHRwczovL2lhbS5lYnJhaW5zLmV1L2F1dGgvcmVhbG1zL2hicCIsImF1ZCI6WyJpbWdfc3ZjIiwib3BlbnNoaWZ0IiwiaGFyYm9yIiwidGVhbSIsInBsdXMiLCJqdXB5dGVyaHViLW9wZW5zaGlmdC1wcmV2aWV3IiwianVweXRlcmh1YiIsInh3aWtpIiwib3BlbnNoaWZ0LWpzYyIsImFjY291bnQiLCJvcGVuc2hpZnQtZGV2IiwiZ3JvdXAiXSwic3ViIjoiMDVmOGVjYzMtNDkzYi00OTdlLTkyMDktNDYxMTdlNGYyNWVmIiwidHlwIjoiQmVhcmVyIiwiYXpwIjoianVweXRlcmh1Yi1qc2MiLCJzZXNzaW9uX3N0YXRlIjoiYTk3N2NiOGUtOTczYy00Yzc2LWE1N2ItMTFjMDlkZWE0MGFiIiwiYWNyIjoiMCIsImFsbG93ZWQtb3JpZ2lucyI6WyJodHRwczovL2xhYi5qc2MuZWJyYWlucy5ldSJdLCJyZWFsbV9hY2Nlc3MiOnsicm9sZXMiOlsiY29sbGFib3JhdG9yeV9tZW1iZXIiLCJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIl19LCJzY29wZSI6InByb2ZpbGUgY29sbGFiLmRyaXZlIG9mZmxpbmVfYWNjZXNzIGNsYi53aWtpLndyaXRlIGNsYi53aWtpLnJlYWQgdGVhbSBjbGIuZHJpdmU6d3JpdGUgcm9sZXMgZW1haWwgb3BlbmlkIGNsYi5kcml2ZTpyZWFkIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsIm5hbWUiOiJFc3BlbiBIYWdlbiIsIm1pdHJlaWQtc3ViIjoiMjU3NDMxIiwicHJlZmVycmVkX3VzZXJuYW1lIjoiZWhhZ2VuIiwiZ2l2ZW5fbmFtZSI6IkVzcGVuIiwiZmFtaWx5X25hbWUiOiJIYWdlbiIsImVtYWlsIjoiZXNwZW4uaGFnZW5Abm1idS5ubyJ9.txqzsYXt97UVtuaAHl_iubAiJGtwUKsNkJK81evSUBxGd-CLa6qRHQNkSJbAM0NSzh0r6kP6QLP5Pz7PsUMmj1vFX0WnCJa75GdeSRbBUddSy12lPcMwXbXcfsm3LdZ_3xm7qomoe0I-kJ5aPlnXP33pgoFp3L2K_mdO7NPFn2OgYJ5Zej5vLVAMwfNey74WnMLQotzmq98B5uYOOT5-WPmOYk423igwRs1hUXWxgyZP1qmDeRYcrqDEb7zuxryX-SH93XhFW6QZ2B07qieT6S4LwGlzUKxfkJEoaAnB0Ifty_rj92REFsJfMBFoIciudfx9xIo4q014-zHi6Pk9Vw']},\n",
       " 'log': ['Mon Nov 22 12:31:12 CET 2021: Created with ID 309c5c4d-4916-4582-86e7-4754813ba497',\n",
       "  \"Mon Nov 22 12:31:12 CET 2021: Created with type 'JSON'\",\n",
       "  \"Mon Nov 22 12:31:12 CET 2021: Client: Name: UID=espen.hagen@nmbu.no\\nXlogin: uid: [hagen2], gids: [icei-hbp-2020-0004, addingOSgroups: true]\\nRole: user: role from attribute source\\nQueues: [batch:develgpus, selected=batch]\\nSecurity tokens: User: UID=espen.hagen@nmbu.no\\nClient's original IP: 134.94.88.93\",\n",
       "  'Mon Nov 22 12:31:14 CET 2021: No staging in needed.',\n",
       "  'Mon Nov 22 12:31:14 CET 2021: Status set to READY.'],\n",
       " '_links': {'action:start': {'description': 'Start',\n",
       "   'href': 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core/jobs/309c5c4d-4916-4582-86e7-4754813ba497/actions/start'},\n",
       "  'action:restart': {'description': 'Restart',\n",
       "   'href': 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core/jobs/309c5c4d-4916-4582-86e7-4754813ba497/actions/restart'},\n",
       "  'workingDirectory': {'description': 'Working directory',\n",
       "   'href': 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core/storages/309c5c4d-4916-4582-86e7-4754813ba497-uspace'},\n",
       "  'self': {'href': 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core/jobs/309c5c4d-4916-4582-86e7-4754813ba497'},\n",
       "  'details': {'description': 'BSS job details',\n",
       "   'href': 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core/jobs/309c5c4d-4916-4582-86e7-4754813ba497/details'},\n",
       "  'action:abort': {'description': 'Abort',\n",
       "   'href': 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core/jobs/309c5c4d-4916-4582-86e7-4754813ba497/actions/abort'},\n",
       "  'parentTSS': {'description': 'Parent TSS',\n",
       "   'href': 'https://zam2125.zam.kfa-juelich.de:9112/JUSUF/rest/core/sites/110f9440-2b6f-4f2c-adb4-e89c02c23cb7'}},\n",
       " 'resourceStatusMessage': 'N/A',\n",
       " 'siteName': 'JUSUF',\n",
       " 'consumedTime': {'postCommand': 'N/A',\n",
       "  'total': 'N/A',\n",
       "  'stage-out': 'N/A',\n",
       "  'queued': 'N/A',\n",
       "  'preCommand': 'N/A',\n",
       "  'main': 'N/A',\n",
       "  'stage-in': '0'},\n",
       " 'acl': [],\n",
       " 'submissionTime': '2021-11-22T12:31:14+0100',\n",
       " 'statusMessage': '',\n",
       " 'tags': [],\n",
       " 'currentTime': '2021-11-22T12:31:14+0100',\n",
       " 'resourceStatus': 'READY',\n",
       " 'batchSystemID': 'N/A',\n",
       " 'terminationTime': '2021-12-22T12:31:12+0100',\n",
       " 'name': 'UNICORE_Job',\n",
       " 'queue': 'N/A',\n",
       " 'status': 'READY'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'  warn(mssg)\\n',\n",
      " b'/usr/local/lib/python3.9/dist-packages/LFPy/cell.py:182: UserWarning: 18 sec'\n",
      " b\"tions detected! Consider setting 'delete_sections=True'\\n\",\n",
      " b'  warn(mssg)\\n',\n",
      " b'/usr/local/lib/python3.9/dist-packages/LFPy/cell.py:182: UserWarning: 18 sec'\n",
      " b\"tions detected! Consider setting 'delete_sections=True'\\n\",\n",
      " b'  warn(mssg)\\n']\n",
      "[b't = 300.0 ms\\n',\n",
      " b't = 400.0 ms\\n',\n",
      " b't = 500.0 ms\\n',\n",
      " b't = 600.0 ms\\n',\n",
      " b't = 700.0 ms\\n',\n",
      " b't = 800.0 ms\\n',\n",
      " b't = 900.0 ms\\n',\n",
      " b't = 1000.0 ms\\n',\n",
      " b't = 1100.0 ms\\n',\n",
      " b't = 1200.0 ms\\n']\n"
     ]
    }
   ],
   "source": [
    "# wait while job is running and track progress\n",
    "while job.is_running():\n",
    "    clear_output()\n",
    "    # STDERR output (if any)\n",
    "    try:\n",
    "        stderr = job.working_dir.stat('stderr')\n",
    "        #pprint(stderr.raw().readlines()[:5])\n",
    "        pprint(stderr.raw().readlines()[-5:])\n",
    "    except:\n",
    "        print('no stderr file to read yet')\n",
    "    # STDOUT output\n",
    "    try:\n",
    "        stdout = job.working_dir.stat('stdout')\n",
    "        #pprint(stdout.raw().readlines()[:10])\n",
    "        pprint(stdout.raw().readlines()[-10:])\n",
    "    except:\n",
    "        print('no stdout file to read yet')\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['example_network_output/', 'stderr', 'BallAndStickTemplate.hoc', 'example_network.py', 'bss_submit_1637580709170', 'example_network_output.tar', 'stdout', '.UNICORE_POST_0/', '.UNICORE_PRE_0/', 'UNICORE_Job_1637580709170', 'UNICORE_SCRIPT_EXIT_CODE', 'BallAndStick.hoc', 'lfpymaster.sif'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.working_dir.listdir().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'\\n',\n",
      " b'  Preparing the environment for use of 2020 stage.\\n',\n",
      " b'\\n',\n",
      " b'\\n',\n",
      " b'  Preparing the environment for use of requested stage ( 2020 ).\\n']\n",
      "[b'  warn(mssg)\\n',\n",
      " b'/usr/local/lib/python3.9/dist-packages/LFPy/cell.py:182: UserWarning: 18 sec'\n",
      " b\"tions detected! Consider setting 'delete_sections=True'\\n\",\n",
      " b'  warn(mssg)\\n',\n",
      " b'/usr/local/lib/python3.9/dist-packages/LFPy/cell.py:182: UserWarning: 18 sec'\n",
      " b\"tions detected! Consider setting 'delete_sections=True'\\n\",\n",
      " b'  warn(mssg)\\n']\n"
     ]
    }
   ],
   "source": [
    "# STDERR output (if any)\n",
    "stderr = job.working_dir.stat('stderr')\n",
    "pprint(stderr.raw().readlines()[:5])\n",
    "pprint(stderr.raw().readlines()[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'numprocs=256\\n',\n",
      " b'Connected population E to E by 419479 connections and 838923 synapses\\n',\n",
      " b'Connected population E to I by 104392 connections and 208730 synapses\\n',\n",
      " b'Connected population I to E by 105115 connections and 525650 synapses\\n',\n",
      " b'Connected population I to I by 26100 connections and 130749 synapses\\n',\n",
      " b't = 100.0 ms\\n',\n",
      " b't = 200.0 ms\\n',\n",
      " b't = 300.0 ms\\n',\n",
      " b't = 400.0 ms\\n',\n",
      " b't = 500.0 ms\\n']\n",
      "[b't = 300.0 ms\\n',\n",
      " b't = 400.0 ms\\n',\n",
      " b't = 500.0 ms\\n',\n",
      " b't = 600.0 ms\\n',\n",
      " b't = 700.0 ms\\n',\n",
      " b't = 800.0 ms\\n',\n",
      " b't = 900.0 ms\\n',\n",
      " b't = 1000.0 ms\\n',\n",
      " b't = 1100.0 ms\\n',\n",
      " b't = 1200.0 ms\\n']\n"
     ]
    }
   ],
   "source": [
    "# STDOUT output\n",
    "stdout = job.working_dir.stat('stdout')\n",
    "pprint(stdout.raw().readlines()[:10])\n",
    "pprint(stdout.raw().readlines()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download simulation output\n",
    "job.working_dir.stat('example_network_output.tar').download('example_network_output.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill job, clean up files on the remote\n",
    "job.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untar output to folder example_network_output\n",
    "!tar -xf example_network_output.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./example_network_output/population_RANK_0.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9f53d433c8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell morphologies on one particular MPI process\n",
    "IFrame(\"./example_network_output/population_RANK_0.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./example_network_output/spike_raster.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9f53d43dd8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spike raster plot\n",
    "IFrame(\"./example_network_output/spike_raster.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./example_network_output/extracellular_potential.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9f53cd4518>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracellular potentials of each population and in total\n",
    "IFrame(\"./example_network_output/extracellular_potential.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"./example_network_output/current_dipole_moment.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9f53cd4e80>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current dipole moment\n",
    "IFrame(\"./example_network_output/current_dipole_moment.pdf\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
